### SFR-RAG【精简检索】
> **精简检索**：像个精练的参考顾问，体积虽小但功能精准，既能理解需求又懂得寻求外部帮助，保证回答既准确又高效。
>

* 发表时间：2024.09.16
* 论文名称：[SFR-RAG: Towards Contextually Faithful LLMs](https://arxiv.org/abs/2409.09916)
* 论文地址：[https://arxiv.org/abs/2409.09916](https://arxiv.org/abs/2409.09916)
* Github 地址：

#### 一、论文动机

随着大型语言模型（LLM）的兴起，生成式AI成为关键领域。LLM能根据各种提示生成复杂输出，其中检索增强生成（RAG）是值得注意的领域，它将外部信息集成到LLM中以提高事实准确性。RAG专门解决生成可靠、与上下文相关的信息的需求，已成为解决基于知识任务的核心，这些任务中模型需根据外部来源生成答案。

#### 二、论文思路

SFR-RAG模型包含函数调用功能，能与外部工具动态交互以检索高质量上下文信息。其创新方法包括一个新颖的聊天模板，添加了“Thought”和“Observation”两个关键角色。Thought角色使模型能内部进行多步骤推理，Observation角色捕获模型过程中检索到的外部信息。这种结构使SFR-RAG区分信息处理步骤并生成准确、用户友好的响应。模型还经微调能抵御低质量或不相关上下文，区别于传统LLM。

#### 三、实验设计与结果

实验结果证明了SFR-RAG的成功，特别是在ContextualBench评估套件中。该套件包含七个上下文任务，旨在测试模型生成准确、与上下文相关答案的能力。尽管参数少得多，SFR-RAG在这七项任务中的三项取得了最先进的结果，优于GPT-4o等更大模型。例如，在2WikiHopQA中，SFR-RAG性能比GPT-4o提高了25%。它还在其他基准测试中表现出色，包括自然问题和音乐。即使上下文信息被更改或包含相互矛盾信息时，SFR-RAG性能依然稳健。

#### 四、论文总结

SFR-RAG通过解决大型模型面临的常见问题，在检索增强生成方面取得重大进展。其90亿参数数量使其能高效运行同时保持高精度和可靠性。创新功能使SFR-RAG处理复杂多步骤推理，同时避免幻觉和不相关上下文生成的缺陷。它在各种基准测试中的出色表现，突出了较小、经微调模型在生成准确、基于上下文输出方面的潜力。SFR-RAG代表了向更高效、更可靠模型的转变，这些模型能更好应对外部上下文处理的挑战。

## 致谢

* 参考：[https://mp.weixin.qq.com/s/yrmtBqP4bmQ2wYZM7F24Yg](https://mp.weixin.qq.com/s/yrmtBqP4bmQ2wYZM7F24Yg)