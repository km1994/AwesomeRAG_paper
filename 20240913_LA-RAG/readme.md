### LA-RAG【方言通】
> **方言通**：像个精通各地方言的语言专家，通过细致的语音分析和上下文理解，不仅能准确识别标准普通话，还能听懂带有地方特色的口音，让AI与不同地区的人都能无障碍交流。
>

* 发表时间：2024.09.13
* 论文名称：[LA-RAG:Enhancing LLM-based ASR Accuracy with Retrieval-Augmented Generation](https://arxiv.org/abs/2409.08597)
* 论文地址：[https://arxiv.org/abs/2409.08597](https://arxiv.org/abs/2409.08597)
* Github 地址：

#### 一、论文动机

文章首先指出，将语音信息整合到LLM中以提高ASR准确性的研究日益增多。早期研究通常将纯文本转录输入LLM，结合ASR的N最佳结果和指令来提示LLM进行错误纠正。这些方法中，LLM主要作为文本重排器或标记选择器。其他研究尝试将预训练的ASR模型（通常是语音编码器部分）与LLM结合，通过模态适配器（如Qformer、注意力或投影）来对齐语音特征空间与LLM的文本空间。这些方法通常通过利用丰富的声学信号来提高性能，但它们的性能上限往往受限于语音编码器的能力，尤其是在训练和测试数据的声学特征不匹配的情况下，例如在口音场景中，编码器训练不足，正确的标记不会出现在N最佳转录中。

#### 二、论文思路

LA-RAG范式通过利用细粒度的标记级语音数据存储和语音到语音检索机制，增强LLM的上下文学习（ICL）能力，从而提高ASR准确性。具体来说，LA-RAG包括以下四个主要部分：

1. **语音分词器（Speech Tokenizer）**：使用预训练的AED/CTC模型提取语音转录对的中间表示，生成与文本标记对齐的语音标记。
2. **数据存储创建（Datastore Creation）**：利用语音分词器对每个训练数据进行处理，生成语音-文本键值对，并存储对应的序列作为LLM的最终提示示例。
3. **语音检索（Speech Retrieval）**：将数据存储组织为语音倒排索引，使用与数据库创建阶段相同的语音分词器对输入语音进行对齐，生成查询嵌入，通过分组和过滤策略获取序列级别的相似示例。
4. **LLM提示（LLM Prompt）**：将对齐的语音标记序列输入语音适配器，与LLM标记空间和维度对齐。使用LoRA进行参数高效的微调，学习语音标记到正确文本标记的映射关系，使LLM能够在推理阶段通过ICL学习正确的文本标记。

#### 三、实验设计与结果

- 实验设计：作者使用了普通话和方言数据集来评估预训练ASR模型在充分和不足训练场景下的性能。数据集包括AISHELL-1和KeSpeech的子方言数据集。实验中使用了Whisper-Medium模型作为基础ASR系统，并测试了CTC和AED两种语音分词方法。LLM解码采用了LLaMA 3 8B模型，并集成了LoRA适配器。检索使用FAISS库实现，设置k值为128，序列过滤阈值为0.5。评估指标为字符错误率（CER）。
- 实验结果：LA-RAG在普通话和中国方言数据集上显著提高了ASR准确性，特别是在处理口音变化时。与现有方法相比，LA-RAG在所有方法中实现了最低的CER，尤其是在口音测试集上，性能提升更为显著。这表明LA-RAG能够帮助LLM学习发音和正确标记之间的映射关系，这对于ASR模型可能未充分学习映射关系的口音场景特别有用。

#### 四、论文总结

LA-RAG通过利用细粒度的语音数据存储和预训练CTC和AED模型实现的精确标记级对齐，显著提高了基于LLM的ASR准确性，尤其是在口音变化场景中。实验结果表明，该方法在各种数据集上都取得了显著的性能提升，包括普通话和中国方言，显著降低了CER。未来的工作计划将LA-RAG方法推广到其他任务和语言的语音识别中。

## 致谢

* 参考：[https://mp.weixin.qq.com/s/oiDffH1_0JiGpVGw83-guQ](https://mp.weixin.qq.com/s/oiDffH1_0JiGpVGw83-guQ)
