### RAE【智能编辑】
> **智能编辑**：像个细心的新闻编辑，不仅会深入挖掘相关事实，还能通过连环推理找出容易被忽略的关键信息，同时懂得删减冗余内容，确保最终呈现的信息既准确又精炼，避免"说得天花乱坠却不靠谱"的问题。
>

* 发表时间：2024.03.28
* 论文名称：[Retrieval-enhanced Knowledge Editing in Language Models for Multi-Hop Question Answering](https://arxiv.org/abs/2403.19631)
* 论文地址：[https://arxiv.org/abs/2403.19631](https://arxiv.org/abs/2403.19631)
* Github 项目：[https://github.com/sycny/RAE](https://github.com/sycny/RAE)

#### 一、论文动机

- **问题背景**：LLMs在问答任务中表现出色，但在处理多跳问题时，需要更新和整合多个知识点。现有的模型编辑方法在处理这些复杂联系时存在困难，容易生成过时或不正确的回答.

#### 二、论文思路

![](20240328_RAE/img/v2-c6d4d097f1cd2745779865d48da2bc17_1440w.png)

- **核心概念**：RAE框架通过检索和编辑相结合的方法，增强LLMs在多跳问答中的表现.
- **关键组成部分**：
  1. **外部知识图谱**：存储编辑过的事实和未编辑的事实，为检索提供知识基础.
  2. **基于互信息的检索**：通过最大化问题和检索到的子图之间的互信息，识别与问题最相关的知识子图.
  3. **冗余知识剪枝**：使用编辑不确定性评估检索到的事实集，剪除冗余或不相关事实，提高编辑准确性.
  4. **上下文学习编辑**：结合经过剪枝的事实集和编辑模板，通过LLMs的上下文学习能力生成准确答案.
  5. **编辑模板**：指导LLMs如何结合问题和事实产生正确输出的特定提示结构.

#### 三、实验设计与结果

- **实验设置**：在不同大小的语言模型上进行评估，验证RAE在提供准确答案和更新知识方面的能力.
- **结果**：RAE在处理多跳问题时，相比于现有基线方法，显著提高了编辑后的模型输出的准确性.

#### 四、论文创新点

1. 检索增强型知识编辑框架
   1. **结合检索与编辑**：传统的知识编辑方法通常依赖于直接修改模型参数或知识库，而RAE框架通过检索增强的方式，结合了检索和编辑的优势。它首先通过检索获取与问题相关的知识，然后对这些知识进行编辑和整合，从而更好地适应多跳问答任务的需求.
   2. **多跳问题的针对性设计**：针对多跳问答任务中知识点之间复杂联系的特点，RAE框架专门设计了检索和编辑策略。通过链式事实的识别和冗余知识的剪枝，能够更准确地捕捉和整合与问题相关的多个知识点.
2. 基于互信息的检索方法
   1. **互信息最大化**：传统的检索方法多基于简单的相似性搜索，容易遗漏相关信息。RAE框架通过最大化问题和检索到的子图之间的互信息，能够更全面地识别与问题最相关的知识子图。这种方法利用了LLMs的推理能力，提高了检索的准确性和相关性.
   2. **链式事实识别**：通过链式事实的识别，RAE能够捕捉到知识点之间的逻辑关系和因果链，弥补了简单相似性搜索的不足，更好地支持多跳推理过程.
3. 冗余知识剪枝策略
   1. **编辑不确定性评估**：引入编辑不确定性来评估检索到的事实集，通过剪除冗余或不相关事实，提高了编辑的准确性和效率。这一策略有助于减少模型输出的不确定性，避免生成错误或不一致的答案.
   2. **提高编辑效率**：通过剪枝策略，RAE框架能够更高效地处理大量的检索结果，避免在不必要的信息上浪费计算资源，从而提高了整体的编辑效率.
4. 上下文学习编辑方法
   1. **结合编辑模板**：利用编辑模板指导LLMs如何结合问题和事实来产生正确的输出。这种特定的提示结构能够更好地引导模型进行上下文学习，生成准确且连贯的答案.
   2. **上下文学习能力的利用**：充分发挥LLMs的上下文学习能力，通过结合经过剪枝的事实集和问题上下文，生成更加准确和符合逻辑的答案.

#### 五、论文总结

- **优势**：RAE框架通过有效的检索和编辑策略，能够更好地处理多跳问答中的复杂知识联系，提高模型的回答准确性.
- **应用场景**：适用于需要实时知识更新和复杂知识整合的问答场景.

## 致谢

- https://mp.weixin.qq.com/s/R0N8yexAlXetFyCS-W2dvg


