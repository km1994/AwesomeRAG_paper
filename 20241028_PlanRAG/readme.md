### Plan×RAG【项目经理】
> **项目经理**：先规划后行动，把大任务分解成小任务，安排多个"专家"并行工作。每个专家负责自己的领域，最后由项目经理统筹汇总结果。这种方式不仅更快、更准，还能清楚交代每个结论的来源。
>

* 发表时间：2024.10.28
* 论文名称：[Plan×RAG: Planning-guided Retrieval Augmented Generation](https://arxiv.org/abs/2410.20753)
* 论文地址：[https://arxiv.org/abs/2410.20753](https://arxiv.org/abs/2410.20753)

#### 一、论文动机

Plan×RAG（Planning-guided Retrieval Augmented Generation）旨在通过增强现有的检索增强生成（RAG）框架，**解决大型语言模型（LLM）在复杂查询中的性能、幻觉和归因问题**。

传统的“检索-推理”范式在处理复杂多跳查询时存在局限性：

- **检索局限**：检索到的文档可能不完整或不相关，导致推理过程受限。
- **上下文窗口限制**：大型语言模型的上下文窗口有限，检索到的文档可能无法完全利用。
- **缺乏规划**：传统的“检索-推理”范式缺乏对查询的结构化分解和规划，难以处理复杂的多跳查询。

#### 二、论文思路

![](20241028_PlanRAG/img/v2-2ec15de269454ec9a9581a5aa01e5969_1440w.png)

Plan×RAG（Planning-guided Retrieval Augmented Generation）框架的实现主要包括以下几个关键步骤和组件：

- **生成推理计划（Reasoning Plan）**
  - **推理有向无环图（DAG）**：使用大型语言模型（如GPT-4）生成一个推理计划，表示为一个有向无环图（DAG）。这个DAG将原始查询分解为相互关联的原子子查询（Atomic Sub-queries）。
  - **结构化分解**：每个子查询只依赖于其父节点的答案，确保推理过程遵循马尔可夫假设（Markov Assumption），即每个子查询的答案只依赖于其直接父节点的答案。
- **插拔式专家系统（Plug-and-Play Experts）**
  - **动态查询专家（Dynamic Query Expert）**：负责生成子查询，并确保子查询之间的马尔可夫依赖关系。动态查询专家将父节点的答案嵌入到子查询中，生成完整的子查询。
  - **批评家专家（Critic Expert）**：评估生成过程中是否需要额外信息，动态触发检索。批评家专家分析当前上下文和生成任务，决定是否需要检索额外信息。
  - **相关性专家（Relevance Expert）**：确保选择最相关的文档进行检索，减少上下文窗口的使用。相关性专家对检索到的文档进行相关性评分、排序和选择。
  - **聚合器专家（Aggregator Expert）**：将多个子查询的答案整合为对原始查询的综合响应。聚合器专家确保最终响应全面、平衡地覆盖原始查询的所有方面。
- **并行化和信息流管理**
  - **并行处理**：DAG结构允许同一深度的子查询并行处理，显著提高了系统的效率。不同深度的子查询可以独立处理，减少了整体推理时间。
  - **相关信息流动**：DAG结构确保只有相关的信息在子查询之间流动，抽象掉不必要的信息，提高了上下文利用的效率。
- **动态检索和生成**
  - **动态检索**：在生成每个子查询的答案时，Plan×RAG可以根据需要动态触发检索，确保在需要时获取额外信息。批评家专家负责评估生成过程中是否需要额外信息，动态触发检索。
  - **相关性过滤**：相关性专家确保选择最相关的文档进行检索，减少上下文窗口的使用，提高检索效率。
- **增强归因和可解释性**
  - **归因设计**：通过将每个子查询的生成内容与单个检索文档直接关联，Plan×RAG确保了生成内容的归因，增强了系统的可解释性和可信度。
  - **单一文档检索**：默认配置下，相关性专家确保每个子查询只检索一个最相关的文档，进一步增强了归因能力。
- **调试和回溯**
  - **调试能力**：DAG结构提供了强大的调试能力，允许系统回溯到错误的生成节点，分析和纠正错误。通过分析DAG和相应的子查询，可以识别和修正错误的生成内容。
  - **回溯机制**：在识别错误节点后，可以仅重新生成受影响的路径，并重新运行聚合器，确保最终生成的响应是正确的。

#### 三、具体实现步骤

1. 生成推理DAG：
   1. 使用GPT-4生成推理DAG，将原始查询分解为多个子查询。
   2. 每个子查询包含一个特殊标签（如<ALJ>），用于动态嵌入父节点的答案。
2. 处理每个子查询：
   1. 按照DAG的拓扑顺序处理每个子查询。
   2. 对于每个子查询，动态查询专家生成完整的子查询。
   3. 批评家专家评估是否需要检索额外信息，动态触发检索。
   4. 相关性专家选择最相关的文档进行检索。
   5. 生成器语言模型（如Llama3-8B-instruct）生成子查询的答案。
3. 整合答案：
    1. 聚合器专家将所有子查询的答案整合为对原始查询的综合响应。
4. 调试和回溯：
   1. 如果生成的答案有误，通过分析DAG和相应的子查询，识别和修正错误。
   2. 仅重新生成受影响的路径，并重新运行聚合器，确保最终生成的响应是正确的。

#### 四、实验设计与结果

- 数据集
  - HotpotQA：多跳问答数据集。
  - StrategyQA：需要多步推理的问答数据集。
  - ARC-Challenge：科学考试问答数据集。
  - PopQA：单跳问答数据集。
- 基线方法
  - Vanilla LLMs：不使用检索的LLMs，如GPT-3.5、Llama2-7B、Llama2-13B和Llama3-8B。
  - 标准RAG：使用LLMs的RAG方法。
  - Self-RAG：自反思的RAG方法。
  - RQ-RAG：动态查询重写和分解的RAG方法。
- 性能对比
  - HotpotQA：Plan×RAG的Accuracy为35.67%，F1 Score为39.68%。
  - StrategyQA：Plan×RAG的Accuracy为69.49%，F1 Score为64.03%。
  - ARC-Challenge：Plan×RAG的Accuracy为74.12%，F1 Score为81.30%。
  - PopQA：Plan×RAG的Accuracy为36.09%，F1 Score为35.20%。
- LLM评估
  - 使用GPT-3.5-Turbo作为外部评估器，比较Self-RAG和Plan×RAG在PopQA数据集上的表现。尽管传统准确率指标显示Plan×RAG与Self-RAG之间存在差距，但LLM-Eval指标显示两者生成的答案在语义上非常相似，差距仅为2.09%和3.32%。
- 消融研究
  - 批评家专家的有效性：批评家专家通过动态触发检索，显著减少了检索次数，同时保持了几乎相同的性能。在1500个HotpotQA查询中，批评家专家配置比始终检索配置减少了600次检索，仅导致0.5%的准确率下降和0.80的F1分数下降。
  - 相关性专家的有效性：相关性专家通过过滤噪声检索，显著提高了系统性能。在1500个HotpotQA查询中，相关性专家配置的准确率为39.33%，F1分数为42.01%，而无相关性专家配置的准确率为31.60%，F1分数为36.18%。

#### 五、论文总结

Plan×RAG通过引入推理计划和插拔式专家系统，解决了传统RAG方法在处理复杂查询时的局限性，显著提高了系统的性能、准确性和可解释性。其设计使其能够与任何预训练的LLM兼容，无需微调，具有广泛的适用性。

## 致谢

* 参考：[https://mp.weixin.qq.com/s/I_-NDGzd7d8l4zjRfCsvDQ](https://mp.weixin.qq.com/s/I_-NDGzd7d8l4zjRfCsvDQ)