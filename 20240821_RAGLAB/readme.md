### RAGLAB【竞技场】
> **竞技场**：让各种算法可以在相同的规则下进行公平竞争和比较，就像科学实验室里的标准化测试流程，确保每个新方法都能得到客观透明的评估。
>

* 发表时间：2024.08.21
* 论文名称：[RAGLAB: A Modular and Research-Oriented Unified Framework for Retrieval-Augmented Generation](https://arxiv.org/abs/2408.11381)
* 论文地址：[https://arxiv.org/abs/2408.11381](https://arxiv.org/abs/2408.11381)
* Github 地址：[https://github.com/fate-ubw/RAGLab](https://github.com/fate-ubw/RAGLab)

#### 一、论文动机

- **RAG技术的重要性**：RAG通过结合大型语言模型（LLMs）的生成能力和外部数据检索来提高回答的准确性，但在研究和开发过程中面临两大主要问题：
  - 许多已发表的成果要么不开源，要么难以搭建环境，导致研究人员不得不从零开始研发新算法。
  - 新的RAG算法不断涌现，但这些算法在基本组件和评估方法上不统一，难以准确评估改进效果。

#### 二、论文思路

![](20240821_RAGLAB/img/v2-8b7590aa7bd5ee63f71a37d1f4a04211_1440w.png)

- **目标**：提供一个面向研究人员的RAG工具包，用于对现有RAG算法进行公平比较，并简化新算法的开发流程。
- **整体架构**：RAGLAB的整体架构包括多个关键组件，如检索器、语料库、生成器、指令实验室、训练器、数据集和指标。
- **检索器**：
  - 整合了两个高性能的基于BERT的模型：Contriever和ColBERT。
  - 统一了不同检索器类的查询接口，方便用户在各种检索器之间无缝切换。
  - 设计了检索器服务器和客户端架构，实现高并发访问。
  - 实现了检索缓存机制，存储初始查询结果及其检索到的知识，提高查询效率。

- **语料库**：
  - 提供了两个版本的预处理维基百科语料库，基于DPR项目开源的2018年数据和FactScore开源的2023年数据。
  - 为ColBERT和Contriever模型预先构建了索引和嵌入。
  - 开源了所有处理脚本，方便研究人员直接下载预处理的维基百科语料库及其相应的索引和嵌入。

- **生成器**：
  - 集成了Huggingface Transformers和VLLM，兼容众多开源模型，提供稳定高效的推理性能。
  - 融入了量化和LoRA功能，支持在计算资源有限的情况下使用大型模型。
  - 开发了GPU管理模块，支持在指定GPU上精准分配多个生成器。
  - 支持闭源大型语言模型，如OpenAI模型，未来将扩展到Claude、Gemini和Azure等。

- **指令实验室**：
  - 设计了指令实验室模块，包括系统指令、任务指令和算法指令。
  - 允许用户从3个指令池中高效导入和组合所需的提示。
  - 用户可以在配置设置中调整参数，便于使用不同指令进行对比实验。

- **训练器**：
  - 集成了Accelerate和DeepSpeed库，提供全面且高效的微调能力。
  - 支持LoRA和QLoRA技术，使用户能够在计算资源有限的情况下微调大型模型。

#### 三、实验设计与结果

- **数据集和指标**：
  - 收集了10个广泛使用的测试数据集，涵盖5个不同任务。
  - 提供了3个经典指标（准确性、精确匹配、F1分数）和2个高级指标（FactScore和ALCE）。

#### 四、论文总结

新型RAG算法之间越来越缺乏全面和公平的比较，开源工具的高级抽象导致缺乏透明度，并限制了开发新算法和评估指标的能力。RAGLAB是一个模块化、研究导向的开源库，重现6种算法并构建全面研究生态。借助RAGLAB，我们在10个基准上公平对比6种算法，助力研究人员高效评估和创新算法。


## 致谢

* 参考：[https://mp.weixin.qq.com/s/WSk0zdWZRXMVvm4-_HiFRw](https://mp.weixin.qq.com/s/WSk0zdWZRXMVvm4-_HiFRw)
