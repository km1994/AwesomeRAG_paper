### Self-RAG【反思者】
> **反思者**：在回答问题时，不仅会查阅资料，还会不断思考和检查自己的答案是否准确完整。通过"边说边想"的方式，像一个谨慎的学者一样，确保每个观点都有可靠的依据支持。

* 发表时间：2024.10.23
* 论文名称：[Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection](https://arxiv.org/abs/2310.11511)
* 论文地址：[https://arxiv.org/abs/2410.11511](https://arxiv.org/abs/2410.11511)
* Github 地址：[https://github.com/AkariAsai/self-rag](https://github.com/AkariAsai/self-rag)

#### 一、论文动机

随着LLM+RAG（检索增强）技术在自然语言处理领域的广泛应用，**如何保证检索内容的有效性、验证检索内容对输出结果的支持性以及区分输出结果的来源成为当前技术框架下的主要问题**。

为了解决这些问题，本文提出了一种新的框架——self-RAG（通过自我反思学习检索、生成和批评）。

#### 二、论文思路

- 框架设计

self-RAG框架通过引入特殊的token来实现对检索和生成过程的精细控制。具体流程如下：

1. **按需检索**：在生成过程中，模型通过触发[Retrieve] token决定是否需要检索内容。
2. **并行生成与评价**：模型利用检索到的内容进行生成，并在生成过程中插入评价token（如[Relevant]、[Supported]、[Irrelevant]、[Partially]）来判断检索内容的相关性和支持程度。
3. **筛选输出**：根据评价token对生成的内容进行排序，选择最佳片段作为最终输出。

- 特殊token的定义

self-RAG定义了以下四种特殊token：

1. [Retrieve]：决定是否需要检索内容（取值为yes或no）。
2. [IsREL]：判断检索内容的相关性。
3. [IsSUP]：判断检索内容对生成内容的支持程度。
4. [IsUSE]：判断检索内容的有用性。

- 实现方法

1. 评价模型C。评价模型C用于生成监督数据，辅助生成模型M的训练。其训练目标是预测检索内容的相关性、支持程度和有用性。监督数据通过GPT-4和人工标注的方式收集，以降低标注成本。
2. 生成模型M。 生成模型M基于LLM进行SFT（监督微调），训练过程中加入评价模型C预测的标签信息。模型的训练目标是生成目标内容的同时，生成与检索内容相关的标签信息。
3. 推理过程
   1. 若生成的[Retrieve]标签为yes，则触发检索器召回相关片段。
   2. 利用召回的片段预测评价标签，并根据标签对生成内容进行排序，选择最佳结果。
   3. 若[Retrieve]标签为no，则直接生成目标内容。

#### 三、实验设计与结果

- 性能提升。

在六个问答数据集上，self-RAG相比其他LLM+RAG框架有显著提升，最多可带来5个点以上的性能提升。

- 检索的影响

实验表明，检索对LLM生成效果有显著影响，检索增强的生成结果在质量和事实性上优于不使用检索的结果。

#### 四、优势与不足

- 优势
  - 精细控制：通过特殊token实现对检索和生成过程的精细控制，提升生成内容的质量和验证性。
  - 灵活性：框架设计灵活，可扩展性强，适用于多种LLM和RAG架构。
- 不足
  - 推理成本：生成和判断标签的过程增加了推理成本。
  - 优化空间：标签设计和召回文档的筛选过程仍有优化空间，例如减少标签数量或优化小模型的筛选效率。

#### 五、论文总结

self-RAG框架通过引入特殊token，实现了对检索和生成过程的精细控制，显著提升了LLM+RAG框架的性能。尽管推理成本有所增加，但其在生成质量和事实性上的提升为未来的研究提供了新的方向。


## 致谢

* 参考：[https://mp.weixin.qq.com/s/y-hN17xFyODxzTIfEfm1Vg](https://mp.weixin.qq.com/s/y-hN17xFyODxzTIfEfm1Vg)