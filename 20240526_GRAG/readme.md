# GRAG【侦探】
> **侦探**：不满足于表面线索，深入挖掘文本之间的关联网络，像破案一样追踪每条信息背后的真相，让答案更准确。
>

* 发表时间：2024.05.26
* 论文名称：[GRAG: Graph Retrieval-Augmented Generation](https://arxiv.org/abs/2405.16506)
* 论文地址：[https://arxiv.org/abs/2405.16506](https://arxiv.org/abs/2405.16506)
* Github 项目：[https://github.com/HuieL/GRAG](https://github.com/HuieL/GRAG)

## 一、论文动机

- **RAG模型的局限性**：传统的RAG模型在处理复杂的图结构数据时，忽视了文本之间的联系和数据库的拓扑信息，导致性能瓶颈。例如，在处理科学文献时，仅基于文本相似性的检索方法无法充分利用文献之间的引用关系和主题结构.
- **GRAG模型的动机**：为了解决这一问题，GRAG模型通过考虑文献之间的引用网络和主题分布，将拓扑信息在检索阶段和生成阶段利用起来，提高生成式语言模型的生成质量和图场景下的上下文一致性.

## 二、论文思路

![](20240526_GRAG/img/20250110085121.png)

GRAG模型由四个主要阶段组成，即k阶子图索引、图检索、软剪枝和生成:

1. **k阶子图索引**：对图中的每个节点及其周围的k阶邻居进行编码，并存储其图嵌入.
2. **图检索**：使用预训练语言模型（PLM）将查询转换为向量，并检索与查询最相关的前N个子图.
3. **软剪枝**：在检索到的子图结构中，对与查询不相关的节点和边进行软剪枝，以减少其对最终生成的影响.
4. **生成**：整合剪枝后的文本子图和原始查询，通过图神经网络（GNN）聚合子图内的信息，最后利用文本信息（text tokens）和子图信息（graph token）控制生成.

GRAG模型采用了一种双重提示策略，即硬提示和软提示。

- **硬提示**：将检索到的子图转换为层次化的文本描述，保留拓扑信息和语义细节.
- **软提示**：检索到的子图在剪枝过后通过GNN聚合文本和拓扑信息生成图token，随后用于引导大语言模型的生成过程.

![](20240526_GRAG/img/v2-62880a703d12a6862a76f64da54fed24_1440w.png)

## 三、实验设计与结果

- **数据集**：在两个多跳推理基准（WebQSP和ExplaGraphs）上进行实验，数据集经过预处理将三元组集合转换为图.
- **结果**：GRAG方法在所有指标上均显著优于当前最先进的RAG方法和LLM基线。特别是在生成任务中，GRAG减少了虚假信息的生成，使用GRAG的LLM（即Llama-7b）在未进行微调的情况下，其性能超越了微调后的LLM，显著降低了训练成本.
- **性能指标**：
  - **WebQSP数据集**：GRAG方法的Hit@1指标显著高于其他方法.
  - **ExplaGraphs数据集**：GRAG方法的准确率表现出色.
- **检索效率与模型性能的权衡**：尽管通过编码子图的方式控制检索空间为 \|V\|（节点数量）个子图，检索更多的子图可以提供更全面的上下文信息以提升生成质量，但这同时也会增加计算开销和处理时间。实验表明，合理选择检索的子图数量可以平衡效率和性能.

## 四、论文总结

传统RAG模型在处理复杂的图结构数据时忽视了文本之间的联系和数据库的拓扑信息，从而导致了性能瓶颈。GRAG通过强调子图结构的重要性，显著提升了检索和生成过程的性能并降低幻觉。

## 致谢

- https://mp.weixin.qq.com/s/xLVaFVr7rnYJq0WZLsFVMw