### RAGViz【透视眼】
> **透视眼**：让RAG系统变透明，看得见模型在读哪句话，像医生看X光片一样，哪里不对一目了然。
>

* 发表时间：2024.11.04
* 论文名称：[RAGViz: Diagnose and Visualize Retrieval-Augmented Generation](https://arxiv.org/abs/2411.01751)
* 论文地址：[https://arxiv.org/abs/2411.01751](https://arxiv.org/abs/2411.01751)
* Github 地址：[https://github.com/cxcscmu/RAGViz](https://github.com/cxcscmu/RAGViz)

#### 一、论文动机

- **RAG 的挑战**：RAG 系统通过检索外部文档来增强 LLM 的知识，但现有的 RAG 系统缺乏对检索文档和模型注意力机制的可视化，难以解释生成结果的来源，容易导致“幻觉”（即生成与检索文档无关的内容）。
- **RAGViz 的目标**：提供一个可视化工具，帮助用户分析 LLM 对检索文档的注意力分配，诊断文档的有效性，并识别生成结果中的幻觉来源。

#### 二、论文思路

- RAGViz 的功能

1. **注意力可视化**：
   1. **文档级注意力**：展示生成文本对每个检索文档的总体注意力分数。
   2. **标记级注意力**：允许用户选择特定的生成标记（token），并查看其在检索文档中的注意力分布。
   3. **可视化方式**：通过颜色深浅表示注意力强度，帮助用户直观理解生成结果与检索文档的关系。
2. **文档切换功能**：
   1. 用户可以添加或移除特定文档，观察其对生成结果的影响。
   2. 通过对比原始生成和修改后的生成结果，帮助用户评估文档对生成结果的贡献。
3. **自定义检索文档数量**：
   1. 用户可以指定检索文档的数量，以测试不同数量的文档对生成结果的影响。

- 系统架构

RAGViz 的系统架构包括以下几个关键组件：

1. **ANN（近似最近邻）索引**：用于高效检索与查询最相关的文档。
2. **后端服务器**：处理查询请求，管理检索逻辑，并与检索索引和 LLM 推理服务器交互。
3. **LLM 推理服务器**：运行 LLM 推理任务，生成文本并计算注意力分数。
4. **前端用户界面**：提供交互式界面，允许用户输入查询、选择文档和标记，并显示注意力可视化结果。

#### 三、实验设计与结果

- 数据集：使用 ClueWeb22 和 The Pile 数据集进行测试。
- 模型：使用 Llama-27b 作为 LLM，支持快速推理和注意力分数计算。
- 效率：系统在中等配置的 GPU 节点上运行，查询时间中位数约为 5 秒，适合实时交互。

#### 四、论文总结

RAGViz 是一个强大的工具，通过可视化检索文档的注意力机制，帮助用户更好地理解和改进 RAG 系统。它不仅能够诊断幻觉问题，还能优化检索策略，提升生成结果的质量。作为开源工具，RAGViz 为研究人员和开发者提供了一个灵活的平台，用于分析和改进 RAG 管道。

## 致谢

* 参考：[https://mp.weixin.qq.com/s/A4vjN1eJr7hJd75UH0kuXA](https://mp.weixin.qq.com/s/A4vjN1eJr7hJd75UH0kuXA)